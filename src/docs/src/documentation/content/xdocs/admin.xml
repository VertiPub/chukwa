<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed to the Apache Software Foundation (ASF) under one or more
  contributor license agreements.  See the NOTICE file distributed with
  this work for additional information regarding copyright ownership.
  The ASF licenses this file to You under the Apache License, Version 2.0
  (the "License"); you may not use this file except in compliance with
  the License.  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE document PUBLIC "-//APACHE//DTD Documentation V2.0//EN" "http://forrest.apache.org/dtd/document-v20.dtd">

<document>
  <header>
    <title>Chukwa Administration Guide</title>
  </header>
  <body>

<section>
<title> Purpose </title>
<p> Chukwa is a system for large-scale reliable log collection and processing
with Hadoop. The <a href="design.html">Chukwa design overview</a> discusses the overall architecture of Chukwa.
You should read that document before this one.
The purpose of this document is to help you install and configure Chukwa.</p>
</section>

<section>
<title> Pre-requisites</title>
<p>Chukwa should work on any POSIX platform, but  GNU/Linux is the only
 production platform that has been tested extensively. Chukwa has also been used
 successfully on Mac OS X, which several members of the Chukwa team use for 
 development. </p>
 <p>
 The only absolute software requirements are <a href="http://java.sun.com">Java 1.6
 </a> or better and <a href="http://hadoop.apache.org/" >Hadoop 0.18+</a>.
  

 HICC, the Chukwa
 visualization interface, <a href="#Set+Up+the+Database">requires MySQL 5.1.30+.</a></p>
 <p>
The Chukwa cluster management scripts rely on <code>ssh</code>; these scripts, however,
are not required if you have some alternate mechanism for starting and stopping
daemons.
 </p>
</section>


<section>
<title>Installing Chukwa</title>
<p>A minimal Chukwa deployment has three components: </p>
<ul>
<li> A Hadoop cluster on which Chukwa will store data (referred to as the Chukwa cluster).</li> 
<li> A collector process, that writes collected data to HDFS, the Hadoop file system.</li>
<li> One or more agent processes, that send monitoring data to the collector. 
The nodes with active agent processes are referred to as the monitored source nodes.</li>
</ul> 
<p>In addition, you may wish to run the Chukwa Demux jobs, which parse collected
data, or HICC, the Chukwa visualization tool.</p>
<p></p>
<p></p>
<p></p>

<figure  align="left" alt="Chukwa Components" src="images/components.gif" />

<section>
<title>First Steps </title>

<ol>
<li>Obtain a copy of Chukwa. You can find the latest release on the 
<a href="http://hadoop.apache.org/chukwa/releases.html">Chukwa release page</a>.</li>
<li>Un-tar the release, via <code>tar xzf</code>.</li>
<li>Make sure a copy of Chukwa is available on each node being monitored, and on
each node that will run a collector.</li>
<li>
We refer to the directory containing Chukwa as <code>CHUKWA_HOME</code>. It may
be helpful to set <code>CHUKWA_HOME</code> explicitly in your environment,
but Chukwa does not require that you do so.</li>
</ol>
</section>

<!-- 
<section>
<title>Chukwa Configuration Files </title>
<p>The Chukwa configuration files are located in the CHUKWA_HOME/conf directory.</p>
<ul>
<li> <code>chukwa-env.sh</code> contains environment variables.
</li></ul>
</section>
 -->

<section>
<title>General Configuration</title>

<p>Agents and collectors are configured differently, but part of the process
is common to both. </p>
<ul>
<li>Make sure that <code>JAVA_HOME</code> is set correctly and points to a Java 1.6 JRE. 
It's generally best to set this in <code>conf/chukwa-env.sh</code>.</li>
<li>
In <code>conf/chukwa-env.sh</code>, set <code>CHUKWA_LOG_DIR</code> and
<code>CHUKWA_PID_DIR</code> to the directories where Chukwa should store its
console logs and pid files.  The pid directory must not be shared between
different Chukwa instances: it should be local, not NFS-mounted.
</li>
 <li> Optionally, set CHUKWA_IDENT_STRING. This string is
 used to name Chukwa's own console log files.</li>
<!--
<li>Set <b>either</b> <code>HADOOP_HOME</code> or <code>HADOOP_JAR</code></li>
-->
</ul>
</section>
</section>

<!-- 
</li> <li> Download and un-tar the Chukwa binary.
</li> <li> Configure the components for the Chukwa cluster (see <a href="#Chukwa+Cluster+Deployment">Chukwa Cluster Deployment</a>).
</li> <li> Configure the Hadoop configuration files (see <a href="#Hadoop+Configuration+Files">Hadoop Configuration Files</a>).
</li> <li> Zip the directory and deploy to all nodes in the Chukwa cluster.
</li></ul> 
<p></p>
<p></p>
<p>2. Select one of the source nodes to be monitored: </p>
<ul>
<li> Create a directory for the Chukwa installation (Chukwa will set the environment variable <strong>CHUKWA_HOME</strong> to point to this directory during the install).
</li> <li> Move to the new directory.
</li> <li> Download and un-tar the Chukwa binary.
</li> <li> Configure the components for the source nodes (see <a href="#Monitored+Source+Node+Deployment">Monitored Source Node Deployment</a>).
</li> <li> Configure the Hadoop configuration files (see <a href="#Hadoop+Configuration+Files">Hadoop Configuration Files</a>).
</li> <li> Zip the directory and deploy to all source nodes to be monitored.
</li></ul> 
</section>
 -->

<section>
<title>Agents </title>
<p>Agents are the Chukwa processes that actually produce data. This section
describes how to configure and run them. More details are available in the
<a href="agent.html">Agent configuration guide</a>.</p>

<section>
<title>Configuration</title>
<p>This section describes how to set up the agent process on the source nodes. </p>

<!-- 
<p>Edit <code>$CHUKWA_HOME/conf/agents</code> configuration file. </p>
<p>Create a list of hosts that are running the Chukwa agent:</p>

<source>
localhost
localhost
localhost
</source>
 -->
 
<p>The one mandatory configuration step is to set up 
<code> $CHUKWA_HOME/conf/collectors</code>. This file should contain a list
of hosts that will run Chukwa collectors. Agents will pick a random collector
from this list to try sending to, and will fail-over to another listed collector
on error.  The file should look something like:</p>

<source>
http://&#60;collector1HostName&#62;:&#60;collector1Port&#62;/
http://&#60;collector2HostName&#62;:&#60;collector2Port&#62;/
http://&#60;collector3HostName&#62;:&#60;collector3Port&#62;/
</source>

<p>Edit the CHUKWA_HOME/conf/initial_adaptors configuration file. This is 
where you tell Chukwa what log files to monitor. See
<a href="agent.html#Adaptors">the adaptor configuration guide</a> for
a list of available adaptors.</p>

<p>There are a number of optional settings in 
<code>$CHUKWA_HOME/conf/chukwa-agent-conf.xml</code>:</p>
<ul>
<li>The most important of these is the cluster/group name that identifies the
monitored source nodes. This value is stored in each Chunk of collected data;
you can therefore use it to distinguish data coming from different groups of 
machines.
<source>
 &#60;property&#62;
    &#60;name&#62;chukwaAgent.tags&#60;/name&#62;
    &#60;value&#62;cluster&#61;&#34;demo&#34;&#60;/value&#62;
    &#60;description&#62;The cluster&#39;s name for this agent&#60;/description&#62;
  &#60;/property&#62;
</source>
</li>
<li>
Another important option is <code>chukwaAgent.checkpoint.dir</code>.
This is the directory Chukwa will use for its periodic checkpoints of running adaptors.
It <strong>must not</strong> be a shared directory; use a local, not NFS-mount, directory.
</li>

<li>
Setting the option <code>chukwaAgent.control.remote</code> will disallow remote connections
to the agent control socket.
</li>
</ul>


</section>




<section>
<title>Starting, stopping, and monitoring</title>
<p>To run an agent process on a single node, use <code>bin/chukwa agent</code>.
</p>

<p>
Typically, agents run as daemons. The script <code>bin/start-agents.sh</code> 
will ssh to each machine listed in <code>conf/agents</code> and start an agent,
running in the background. The script <code>bin/stop-agents.sh</code> 
does the reverse.</p>
<p>You can, of course, use any other daemon-management system you like. 
For instance, <code>tools/init.d</code> includes init scripts for running
Chukwa agents.</p>
<p>To check if an agent is working properly, you can telnet to the control
port (9093 by default) and hit "enter". You will get a status message if
the agent is running normally.
</p>
</section>

<section>
<title>Configuring Hadoop for monitoring</title>
<p>
One of the key goals for Chukwa is to collect logs from Hadoop clusters. This section
describes how to configure Hadoop to send its logs to Chukwa. Note that 
these directions require Hadoop 0.20.0+.  Earlier versions of Hadoop do not have
the hooks that Chukwa requires in order to grab MapReduce job logs.</p>
<p>The Hadoop configuration files are located in <code>HADOOP_HOME/conf</code>.
 To setup Chukwa to collect logs from Hadoop, you need to change some of the 
 Hadoop configuration files.</p>
<ol>
	<li>Copy CHUKWA_HOME/conf/hadoop-log4j.properties file to HADOOP_HOME/conf/log4j.properties</li>
	<li>Copy CHUKWA_HOME/conf/hadoop-metrics.properties file to HADOOP_HOME/conf/hadoop-metrics.properties</li>
	<li>Edit HADOOP_HOME/conf/hadoop-metrics.properties file and change @CHUKWA_LOG_DIR@ to your actual CHUKWA log dirctory (ie, CHUKWA_HOME/var/log)</li>	
<!-- <li>ln -s HADOOP_HOME/conf/hadoop-site.xml CHUKWA_HOME/conf/hadoop-site.xml</li>
 -->	
 </ol>
</section>

</section>


<section>
<title>Collectors </title>
<p>This section describes how to set up the Chukwa collectors.
For more details, see <a href="collector.html">the collector configuration guide</a>.</p>

<section>
<title>Configuration</title>
<p>First, edit <code>$CHUKWA_HOME/conf/chukwa-env.sh</code> In addition to 
the general directions given above, you should set <code>
HADOOP_HOME</code>. This should be the Hadoop deployment Chukwa will use to
store collected data.
You will get a version mismatch error if this is configured incorrectly.
</p>

<p>Next, edit <code>$CHUKWA_HOME/conf/chukwa-collector-conf.xml</code>.
The one mandatory configuration parameter is <code>writer.hdfs.filesystem</code>.
This should be set to the HDFS root URL on which Chukwa will store data.
Various optional configuration options are described in <a href="collector.html">the collector configuration guide</a>
and in the collector configuration file itself.
</p>
</section>

<section>
<title>Starting, stopping, and monitoring</title>
<p>To run a collector process on a single node, use <code>bin/chukwa collector</code>.
</p>

<p>
Typically, collectors run as daemons. The script <code>bin/start-collectors.sh</code> 
will ssh to each collector listed in <code>conf/collectors</code> and start a
collector, running in the background. The script <code>bin/stop-collectors.sh
</code> does the reverse.</p>
<p>You can, of course, use any other daemon-management system you like. 
For instance, <code>tools/init.d</code> includes init scripts for running
Chukwa collectors.</p>
<p>To check if a collector is working properly, you can simply access
<code>http://collectorhost:collectorport/chukwa?ping=true</code> with a web browser.
If the collector is running, you should see a status page with a handful of statistics.</p>

</section>

</section>

<section>
<title>Demux and HICC</title>


<!-- 
<section>
<title>Migrate Existing Data From Chukwa 0.1.1</title>
<p>Start the MySQL shell:</p>
<source>
mysql -u root -p
Enter password:
</source>

<p>From the MySQL shell, enter these commands (replace &#60;database_name&#62; with an actual value):</p>
<source>
use &#60;database_name&#62;
source /path/to/chukwa/conf/database_create_table.sql
source /path/to/chukwa/conf/database_upgrade.sql
</source>
</section> -->


<section>
<title>Start the Chukwa Processes </title>

<p>The Chukwa startup scripts are located in the CHUKWA_HOME/tools/init.d directory.</p>
<ul>
<li> Start the Chukwa data processors script (execute this command only on the data processor node):
</li></ul> 
<source>CHUKWA&#95;HOME/tools/init.d/chukwa-data-processors start </source>
<ul>
<li> Create down sampling daily cron job:
</li></ul> 
<source>CHUKWA&#95;HOME/bin/downSampling.sh --config &#60;path to chukwa conf&#62; -n add </source>
</section>


<section>
<title>Set Up the Database </title>
<p>Set up and configure the MySQL database.</p>

<section>
<title>Install MySQL</title>

<p>Download MySQL 5.1 from the <a href="http://dev.mysql.com/downloads/mysql/5.1.html#downloads">MySQL site</a>. </p>
<source>
tar fxvz mysql-&#42;.tar.gz -C $CHUKWA&#95;HOME/opt
cd $CHUKWA&#95;HOME/opt/mysql-&#42;
</source>

<p>
Configure and then copy the my.cnf file to the CHUKWA_HOME/opt/mysql-* directory:
</p>
<source>
./scripts/mysql_install_db
./bin/mysqld_safe&#38;
./bin/mysqladmin -u root create &#60;clustername&#62;
./bin/mysql -u root &#60;clustername&#62; &#60; $CHUKWA&#95;HOME/conf/database_create_table
</source>

<p>Edit the CHUKWA_HOME/conf/jdbc.conf configuration file. </p>
<p>Set the clustername to the MYSQL root URL:</p>
<source>
&#60;clustername&#62;&#61;jdbc:mysql://localhost:3306/&#60;clustername&#62;?user&#61;root
</source>

<p>Download the MySQL Connector/J 5.1 from the  <a href="http://dev.mysql.com/downloads/connector/j/5.1.html">MySQL site</a>, 
and place the jar file in $CHUKWA_HOME/lib.</p>
</section>

<section>
<title>Set Up MySQL for Replication</title>
<p>Start the MySQL shell:</p>
<source>
mysql -u root -p
Enter password:
</source>
<p>From the MySQL shell, enter these commands (replace &#60;username&#62; and &#60;password&#62; with actual values):</p>
<source>
GRANT REPLICATION SLAVE ON &#42;.&#42; TO &#39;&#60;username&#62;&#39;&#64;&#39;&#37;&#39; IDENTIFIED BY &#39;&#60;password&#62;&#39;;
FLUSH PRIVILEGES; 
</source>
</section>

</section>

<!-- 
<section>
<title>Validate the Chukwa Processes </title>

<p>The Chukwa status scripts are located in the CHUKWA_HOME/tools/init.d directory.</p>

 <ul>
<li> To verify that the data processors are functioning correctly: </li>
</ul> 
<source>Visit the Chukwa hadoop cluster&#39;s Job Tracker UI for job status. 
Refresh to the Chukwa Cluster Configuration page for the Job Tracker URL. </source>
</section> -->

<section>
<title>Set Up HICC </title>
<p>The Hadoop Infrastructure Care Center (HICC) is the Chukwa web user interface. To set up HICC, do the following:</p>
<ul>
<li>Download apache-tomcat 6.0.18+ from <a href="http://tomcat.apache.org/download-60.cgi">Apache Tomcat</a> and decompress the tarball to CHUKWA_HOME/opt. </li> 
<li>Copy CHUKWA_HOME/hicc.war to apache-tomcat-6.0.18/webapps. </li> 
<li>Start up HICC by running: </li> 
</ul>
<source>$CHUKWA_HOME/bin/hicc.sh start</source>
<ul>
<li>Point your favorite browser to: http://&#60;server&#62;:8080/hicc  </li> 
</ul>
</section>

</section>



<section>
<title>Troubleshooting Tips</title>

<section>
<title>UNIX Processes For Chukwa Agents</title>

<!-- 
<p>The system metrics data loader process names are uniquely defined by:</p>
<ul>
<li> org.apache.hadoop.chukwa.inputtools.plugin.metrics.Exec sar -q -r -n ALL 55
</li> <li> org.apache.hadoop.chukwa.inputtools.plugin.metrics.Exec iostat -x -k 55 2
</li> <li> org.apache.hadoop.chukwa.inputtools.plugin.metrics.Exec top -b -n 1 -c
</li> <li> org.apache.hadoop.chukwa.inputtools.plugin.metrics.Exec df -l
</li> <li> org.apache.hadoop.chukwa.inputtools.plugin.metrics.Exec CHUKWA_HOME/bin/../bin/netstat.sh
</li></ul> 
-->
<p>The Chukwa agent process name is identified by:</p>
<ul>
<li> org.apache.hadoop.chukwa.datacollection.agent.ChukwaAgent
</li></ul> 
<p>Command line to use to search for the process name:</p>
<ul>
<li> ps ax | grep org.apache.hadoop.chukwa.datacollection.agent.ChukwaAgent
</li></ul> 
</section>

<section>
<title>UNIX Processes For Chukwa Collectors</title>
<p>Chukwa Collector name is identified by:</p>
<ul>
<li> <strong>org.apache.hadoop.chukwa.datacollection.collector.CollectorStub</strong>
</li></ul> 
</section>

<section>
<title>UNIX Processes For Chukwa Data Processes</title>
<p>Chukwa Data Processors are identified by:</p>
<ul>
<li> org.apache.hadoop.chukwa.extraction.demux.Demux
</li> <li>org.apache.hadoop.chukwa.extraction.database.DatabaseLoader
</li> <li>org.apache.hadoop.chukwa.extraction.archive.ChukwaArchiveBuilder
</li></ul> 
<p>The processes are scheduled execution, therefore they are not always visible from the process list.</p>
</section>


<section>
<title>Checks for MySQL Replication </title>
<p>At slave server, MySQL prompt, run:</p>
<source>
show slave status\G
</source>
<p>Make sure both <strong>Slave_IO_Running</strong> and <strong>Slave_SQL_Running</strong> are both "Yes".</p>
<p>Things to check if MySQL replication fails:</p>
<ul>
<li> Make sure grant permission has been enabled on master MySQL server.
</li> <li> Check disk space availability.  
</li> <li> Check Error status in slave status.
</li></ul> 
<p>To reset MySQL replication, run these commands on MySQL:</p>
<source>
STOP SLAVE;
CHANGE MASTER TO
  MASTER&#95;HOST&#61;&#39;hostname&#39;,
  MASTER&#95;USER&#61;&#39;username&#39;,
  MASTER&#95;PASSWORD&#61;&#39;password&#39;,
  MASTER&#95;PORT&#61;3306,
  MASTER&#95;LOG&#95;FILE&#61;&#39;master2-bin.001&#39;,
  MASTER&#95;LOG&#95;POS&#61;4,
  MASTER&#95;CONNECT&#95;RETRY&#61;10;
START SLAVE;
</source>
</section>


<section>
<title> Checks For Disk Full </title>
<p>If anything is wrong, use /etc/init.d/chukwa-agent and CHUKWA_HOME/tools/init.d/chukwa-system-metrics stop to shutdown Chukwa.  
Look at agent.log and collector.log file to determine the problems. </p> 
<p>The most common problem is the log files are growing unbounded. Set up a cron job to remove old log files:  </p>
<source>
 0 12 &#42; &#42; &#42; CHUKWA&#95;HOME/tools/expiration.sh 10 !CHUKWA&#95;HOME/var/log nowait
</source>     
<p>This will set up the log file expiration for CHUKWA_HOME/var/log for log files older than 10 days.</p>
</section>


<section>
<title>Emergency Shutdown Procedure</title>
<p>If the system is not functioning properly and you cannot find an answer in the Administration Guide, execute the kill command. 
The current state of the java process will be written to the log files. You can analyze these files to determine the cause of the problem.</p>
<source>
kill -3 &#60;pid&#62;
</source>

</section>
</section>

</body>
</document>
